# Procesamiento del Lenguaje Natural ‚Äì Trabajos Pr√°cticos

Este repositorio contiene los cuatro trabajos pr√°cticos realizados en el marco de la materia **Procesamiento del Lenguaje Natural**, dictada por el Dr. Rodrigo C√°rdenas Szigety y el Dr. Nicol√°s Vattuone en la carrera de Especializacion en Inteligencia Artificial de la Universidad de Buenos Aires.

Cada notebook aborda un problema distinto del procesamiento de texto, aplicando t√©cnicas modernas de PLN, modelos cl√°sicos y redes neuronales, combinando teor√≠a y pr√°ctica sobre diversos datasets.

---

## üîπ TP1 - Clasificaci√≥n y Similaridad de Textos

**Notebook:** `ResolucionTP1.ipynb`  
**Dataset:** [20 Newsgroups](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)  
**Objetivo:** Analizar similitud sem√°ntica entre documentos y entrenar clasificadores supervisados.

### Contenidos:
- Vectorizaci√≥n con **TF-IDF**.
- C√°lculo de **similaridad coseno** entre documentos.
- Entrenamiento y comparaci√≥n de modelos de clasificaci√≥n:
  - `Multinomial Na√Øve Bayes`
  - `Complement Na√Øve Bayes`
- An√°lisis de similaridad entre palabras transponiendo la matriz documento-t√©rmino.

---

## üîπ TP2 - Word Embeddings y Visualizaci√≥n

**Notebook:** `ResolucionTP2.ipynb`  
**Dataset:** `movie_reviews` de NLTK  
**Objetivo:** Entrenar embeddings de palabras y visualizar relaciones sem√°nticas.

### Contenidos:
- Tokenizaci√≥n y limpieza de texto.
- Entrenamiento de **Word2Vec** (modelo Skip-Gram).
- B√∫squeda de palabras m√°s similares.
- Pruebas de analog√≠as sem√°nticas.
- Visualizaci√≥n de embeddings:
  - Reducci√≥n dimensional con **t-SNE**.
  - Heatmap de **similaridad coseno** entre palabras seleccionadas.

---

## üîπ TP3 - Modelado de Lenguaje con RNN

**Notebook:** `ResolucionTP3.ipynb`  
**Dataset:** Gui√≥n de la serie *Friends* (extra√≠do de un archivo `.txt`)  
**Objetivo:** Entrenar un modelo de lenguaje car√°cter a car√°cter utilizando redes recurrentes.

### Contenidos:
- Limpieza y normalizaci√≥n del corpus.
- Tokenizaci√≥n car√°cter a car√°cter.
- Preparaci√≥n de datos para tareas many-to-many.
- Entrenamiento de un modelo secuencial:
  - `SimpleRNN` con Keras
- Evaluaci√≥n del modelo con **perplejidad (PPL)** y early stopping.

---

## üîπ TP4 - Chatbot Seq2Seq

**Notebook:** `ResolucionTP4.ipynb`  
**Dataset:** Conversaciones del challenge [ConvAI2](http://convai.io/data/)  
**Objetivo:** Construir un chatbot usando una arquitectura encoder-decoder con LSTM.

### Contenidos:
- Limpieza y preprocesamiento de di√°logos.
- Tokenizaci√≥n de secuencias para entrada y salida.
- Definici√≥n del vocabulario y padding de secuencias.
- Preparaci√≥n del dataset para un modelo Seq2Seq.
- Uso de **embeddings** preentrenados (FastText).
- Generaci√≥n de respuestas autom√°ticas con red neuronal recurrente `LSTM`.

---

## üìö Herramientas utilizadas

- **Python**
- **NLTK**, **Gensim**, **Scikit-learn**, **Keras**, **TensorFlow**
- **Matplotlib**, **Seaborn**, **TSNE**, **Pandas**, **NumPy**

---

## üë®‚Äçüè´ Profesores

- Dr. Rodrigo C√°rdenas Szigety  
- Dr. Nicol√°s Vattuone


